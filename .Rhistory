devtools::document()
library(RJDBC)
devtools::document()
library(dplyr)
library(rJava)
library(RJDBC)
#devtools::load_all("/Users/zukow/Downloads/dbplyr")
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "so_survey_2019_hive"
)
rs <- dbSendQuery(conn, "SELECT * FROM survey_results_schema")
row1 <- dbFetch(rs, n = 1)
row1 <- dbFetch(rs, n = 5)
View(row1)
dbListTables(conn)
dbGetTables(conn)
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
dbGetTables(conn)
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
dbGetTables(conn)
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
dbGetTables(conn)
source('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
dbGetTables(conn)
library(dplyr)
library(rJava)
library(RJDBC)
#devtools::load_all("/Users/zukow/Downloads/dbplyr")
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "so_survey_2019_hive"
)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
devtools::load_all("/Users/zukow/Downloads/RHiveS2")
dbListTables(conn)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
r <- dbGetTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
r <- dbGetTables(conn)
r3 <- dbFetch(r)
dbGetTables(conn)
dbDisconnect(conn)
dbListTables(conn)
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "so_survey_2019_hive"
)
dbListTables(conn)
library(dplyr)
library(rJava)
library(RJDBC)
#devtools::load_all("/Users/zukow/Downloads/dbplyr")
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "so_survey_2019_hive"
)
rs <- dbSendQuery(conn, "SELECT * FROM survey_results_schema")
row1 <- dbFetch(rs, n = 5)
View(row1)
library(dplyr)
library(rJava)
library(RJDBC)
#devtools::load_all("/Users/zukow/Downloads/dbplyr")
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "so_survey_2019_hive"
)
dbExistsTable(conn, "survey_results_public")
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "default"
)
dbListTables(conn)
dbListTables(conn)
dbRemoveTable(conn,"test_ext")
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "so_survey_2019_hive"
)
dbListFields(conn, "survey_results_schema")
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
dbListTables(conn)
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "default"
)
dbListTables(conn)
dbListTables(conn,"default")
dbListTables(conn, schema = "default")
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn, schema = "default")
dbListTables(conn)
rs <- dbSendQuery(conn, "show tables")
row1 <- dbFetch(rs, n = 5)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
dbListFields(conn, "test_ext")
dbListTables(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
dbListTables(conn, "testext")
dbListTables(conn, "test_ext")
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn, "test_ext")
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn, "test_ext")
dbListFields(conn, "test_ext")
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn, "test_ext")
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
dbListTables(conn,"test_ext" )
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "default"
)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
dbListTables(conn)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
devtools::load_all("/Users/zukow/Documents/GitHub/HiveS2")
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
is.null(getGeneric("dbGetFields"))
dbListFields(conn, "test_ext")
dbListFields(conn, "test_ext", "test_int")
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
url="jdbc:hive2://localhost:10000",
schema = "so_survey_2019_hive"
)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/HiveS2/sandbox.R', echo=TRUE)
force(s)
library(dplyr)
library(rJava)
library(RJDBC)
#devtools::load_all("/Users/zukow/Downloads/dbplyr")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
setwd("/Users/zukow/Documents")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
show(conn)
show(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
show(conn)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
show(drv)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
show(drv)
dbGetInfo(drv)
dbGetInfo(conn)
show(conn)
dbListTables(conn)
typeof(NULL)
typeof(7)
library(dplyr)
library(rJava)
library(RJDBC)
#devtools::load_all("/Users/zukow/Downloads/dbplyr")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
show(conn)
dsc <- function(conn) {
return(TRUE)
}
dsc(conn)
show(conn)
dsc <- function(conn) {
invisible(TRUE)
}
dsc(conn)
show(conn)
dbDisconnect(conn)
show(conn)
dbGetInfo(conn)
survey_results_public<-tbl(conn, "survey_results_public")
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
survey_results_schema<-tbl(conn, "survey_results_schema")
dsc <- function(conn) {
invisible(TRUE)
}
survey_results_schema<-tbl(conn, "survey_results_schema")
dsc(conn)
survey_results_schema<-tbl(conn, "survey_results_schema")
dsc(conn)
survey_results_public<-tbl(conn, "survey_results_public")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
dbDisconnect(conn)
survey_results_schema<-tbl(conn, "survey_results_schema")
survey_results_public<-tbl(conn, "survey_results_public")
devtools::document()
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
devtools::document()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::document()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
library(RJDBC)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::document()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
library(RJDBC)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
dbDisconnect(conn)
survey_results_schema<-tbl(conn, "survey_results_schema")
library(dplyr)
survey_results_schema<-tbl(conn, "survey_results_schema")
typeof(1.6)
typeof(10809809809809809809)
typeof(18979,890)
typeof(18979.890)
library(dplyr)
library(rJava)
library(RJDBC)
#devtools::load_all("/Users/zukow/Downloads/dbplyr")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "so_survey_2019_hive"
)
hive_result <- dbSendQuery("select * from survey_results_schema")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
hive_result <- dbSendQuery("select * from survey_results_schema")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
hive_result <- dbSendQuery(conn, "select * from survey_results_schema")
dbGetInfo(hive_result)
dbGetInfo(hive_result)
dbColumnInfo(hive_result)
survey_results_schema <- fetch(hive_result)
survey_results_schema <- fetch(conn, hive_result)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
survey_results_schema <- fetch(hive_result, 100)
dbGetInfo(hive_result)
dbHasCompleted(hive_result)
dbColumnInfo(hive_result)
View(survey_results_schema)
devtools::document()
install.packages("DBItest")
devtools::use_testthat()
devtools::use_test("DBItest")
use_testthat()
use_git()
install.packages("devtools")
library(devtools)
use_git()
use_testthat()
use_test()
load_all()
use_test()
check()
check()
check()
detach("package:RJDBC", unload = TRUE)
library(RJDBC)
remove.packages("RJDBC")
install.packages("RJDBC")
check()
install.packages("devtools")
check()
library(devtools)
check()
check()
library(RJDBC)
check()
#' @export
setMethod("dbQuoteIdentifier", c("HiveS2Connection", "character"), function(conn, x, ...) {
if (any(is.na(x))) {
stop("Cannot pass NA to dbQuoteIdentifier()", call. = FALSE)
}
x <- gsub(conn@identifier.quote, paste0(conn@identifier.quote,conn@identifier.quote), enc2utf8(x))
if (length(x) == 0L) {
SQL(character(), names = names(x))
} else {
SQL(paste(conn@identifier.quote, x, conn@identifier.quote, sep = ""), names = names(x))
}
})
check()
remove.packages("DBI")
library(RJDBC)
install.packages("DBI")
library(DBI)
library(devtools)
check()
check()
library(RJDBC)
check()
check()
check()
showMethods("dbQuoteIdentifier")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
rm(list = c(".__T__dbQuoteIdentifier:DBI"))
check()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
check()
check()
devtools::check()
devtools::check()
check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()

# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
sdf <- copy_to(conn, tibble::tibble(x = c(0.9, NA_real_, 1.1)))
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
sdf <- copy_to(conn, tibble::tibble(x = c(0.9, NA_real_, 1.1)))
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
traceback()
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
sdf <- copy_to(conn, tibble::tibble(x = c(0.9, NA_real_, 1.1)))
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
sdf <- copy_to(conn, tibble::tibble(x = c(0.9, NA_real_, 1.1)))
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
sdf <- copy_to(conn, tibble::tibble(x = c(0.9, NA_real_, 1.1)))
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
sdf <- copy_to(conn, tibble::tibble(x = c(0.9, NA_real_, 1.1)))
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
dbSendQuery(conn, "create table foo (test int)")
dbListTables(conn, pattern='*oo')
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
dbSendQuery(conn, "create table foo (test int)")
dbListTables(conn, pattern='*oo')
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
dbSendQuery(conn, "create table foo (test int)")
dbListTables(conn, pattern='*oo')
dbListTables(conn, pattern='*oo')
statement <- paste('SHOW TABLES LIKE', dbQuoteString(conn, paste(pattern)))
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
FALSE
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
Q
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10, y=11:20)
sdf <- copy_to(conn, df, "df2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10, y=11:20)
sdf <- copy_to(conn, df, "df3")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10, y=11:20)
sdf <- copy_to(conn, df, "df4")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10, y=11:20)
sdf <- copy_to(conn, df, "df5")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df <- tibble(x = 1:10, y=11:20)
sdf <- copy_to(conn, df, "df1")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
sdf <- copy_to(conn, tibble::tibble(x = c(0.9, "foo", 1.1)), "df1")
show_query(sdf %>% dplyr::mutate(x = ifelse(x > 1, "good", "bad")))
lf <- lazy_frame(x = 1, y = 2)
l <-inner_join(lf, lf)
View(l)
show_query(l)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df1_df <- tibble(a = 1:3, b = letters[1:3])
df2_df <- tibble(b = letters[1:3], c = letters[24:26])
df1 <- copy_to(conn, df1_df, "df1")
df2 <- copy_to(conn, df2_df, "df2")
show_query(left_join(df2_df, df1_df))
show_query(left_join(df2_df, df1_df) %>% dplyr::arrange(b))
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
show_query(dfo)
View(dfo)
hfi<-left_join(df1, df2) %>% dplyr::arrange(b) %>% collect()
View(hfi)
dbSendQuery(conn, "drop table df1")
dbSendQuery(conn, "drop table df2")
df1_df <- tibble(a = 1:3, b = letters[1:3])
df2_df <- tibble(b = letters[1:3], c = letters[24:26])
df1 <- copy_to(conn, df1_df, "df1")
df2 <- copy_to(conn, df2_df, "df2")
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
hfi<-left_join(df2, df1) %>% dplyr::arrange(b) %>% collect()
View(dfo)
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
hfi<-left_join(df2, df1) %>% dplyr::arrange(b) %>% collect()
l<-identical(dfo,hfi)
dbSendQuery(conn, "drop table df1")
dbSendQuery(conn, "drop table df2")
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df1_df <- tibble(a = 1:3, b = letters[1:3])
df2_df <- tibble(b = letters[1:3], c = letters[24:26])
df1 <- copy_to(conn, df1_df, "df1")
df2 <- copy_to(conn, df2_df, "df2")
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
hfi<-left_join(df2, df1) %>% dplyr::arrange(b) %>% collect()
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
View(hfi)
View(dfo)
dbSendQuery(conn, "drop table df1")
dbSendQuery(conn, "drop table df2")
df1_df <- tibble(a = 1:3, b = letters[1:3])
df2_df <- tibble(b = letters[1:3], c = letters[24:26])
df1 <- copy_to(conn, df1_df, "df1")
df2 <- copy_to(conn, df2_df, "df2")
df1t<-tbl(conn,"df1")%>% collect()
df2t<-tbl(conn,"df2")%>% collect()
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
hfi<-left_join(df2, df1) %>% dplyr::arrange(b) %>% collect()
df1t
df1t<-tbl(conn,"df1")%>% collect()
df1 <- copy_to(conn, df1_df, "df1")
df1_df <- tibble(a = 1:3, b = letters[1:3])
df2_df <- tibble(b = letters[1:3], c = letters[24:26])
df1 <- copy_to(conn, df1_df, "df1")
df2 <- copy_to(conn, df2_df, "df2")
df1t<-tbl(conn,"df1")%>% collect()
df2t<-tbl(conn,"df2")%>% collect()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
df1_df <- tibble(a = 1:3, b = letters[1:3])
df2_df <- tibble(b = letters[1:3], c = letters[24:26])
df1 <- copy_to(conn, df1_df, "df1")
df2 <- copy_to(conn, df2_df, "df2")
df1t<-tbl(conn,"df1")%>% collect()
df2t<-tbl(conn,"df2")%>% collect()
dbSendQuery(conn, "drop table df1")
dbSendQuery(conn, "drop table df2")
df1_df <- tibble(a = 1:3, b = letters[1:3])
df2_df <- tibble(b = letters[1:3], c = letters[24:26])
df1 <- copy_to(conn, df1_df, "df1")
dbSendQuery(conn, "drop table df1")
dbSendQuery(conn, "drop table df2")
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
dbSendQuery(conn, "drop table df1")
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
dbSendQuery(conn, "drop table df1")
dbSendQuery(conn, "drop table df2")
debugSource('~/Documents/GitHub/RHiveS2/sandbox.R', echo=TRUE)
View(l)
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
hfi<-left_join(df1, df2) %>% dplyr::arrange(b) %>% collect()
show_query(dfo)
hfi<-left_join(df1, df2) %>% dplyr::arrange(b) %>% collect()
show_query(hfi)
hfi<-left_join(df1, df2) %>% dplyr::arrange(b)
show_query(hfi)
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
hfi<-left_join(df2, df1) %>% dplyr::arrange(b) %>% collect()
l<-identical(dfo,hfi)
hfi<-left_join(df2, df1) %>% dplyr::arrange(b)
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)
hfi<-left_join(df2, df1) %>% dplyr::arrange(b)
l<-identical(dfo,hfi)
dfo<-left_join(df2_df, df1_df) %>% dplyr::arrange(b)%>% collect()
hfi<-left_join(df2, df1) %>% dplyr::arrange(b)  %>% collect()
l<-identical(dfo,hfi)
dbSendQuery(conn, "drop table df1")
dbSendQuery(conn, "drop table df2")
paste("'e'")
paste0("'e'")
noquote("'e'")
noquote('e')
noquote(e)
mtcars
iris
mf1 <- copy_to(conn, tibble::tibble(x = 1, y = 1, z = 2) %>% group_by(x, y), "df3", overwrite = TRUE )
mf2 <- mf1 %>% summarise(n = n())
eq<-group_vars(mf2)
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
mf1 <- copy_to(conn, tibble::tibble(x = 1, y = 1, z = 2) %>% group_by(x, y), "df3", overwrite = TRUE )
mf2 <- mf1 %>% summarise(n = n())
eq<-group_vars(mf2)
mf1 <- copy_to(conn, tibble::tibble(x = 1, y = 1, z = 2) %>% group_by(x, y), "df3", overwrite = TRUE )%>%collect()
View(mf1)
mf2 <- mf1 %>% summarise(n = n())%>%collect()
View(mf2)
show_query(mf2)
mf2 <- mf1 %>% summarise(n = n())
show_query(mf2)
mf2 <- mf1 %>% summarise(n = n())%>%collect()
eq<-group_vars(mf2)
show_query(mf2)
show_query(mf1)
eq<-group_vars(mf2)
show_query(eq)
mf1 <- copy_to(conn, tibble::tibble(x = 1, y = 1, z = 2) %>% group_by(x, y), "df3", overwrite = TRUE )
show_query(mf1)
mf2 <- mf1 %>% summarise(n = n())
show_query(mf2)
eq<-group_vars(mf2)
show_query(eq)
mf1 <- tibble::tibble(x = 1, y = 1, z = 2) %>% group_by(x, y)
show_query(mf1)
mf2 <- mf1 %>% summarise(n = n())
show_query(mf2)
out <- copy_to(conn, tibble::tibble(x = "a"), "df3", overwrite = TRUE )%>%
group_by(x) %>%
summarise(n = n())
e<-out%>%collect()
q<-tibble::tibble(x = "a", n = 1L)
View(e)
View(q)
View(e)
out <- copy_to(conn, tibble::tibble(x = "a", y="b"), "df3", overwrite = TRUE )%>%
group_by(x) %>%
summarise(n = n())
e<-out%>%collect()
out <- copy_to(conn, tibble::tibble(x = "a"), "df3", overwrite = TRUE )%>%
group_by(x) %>%
summarise(n = n())
show_query(out)
install.packages("dbplyr")
remove.packages("dbplyr")
install_version("dbplyr", version = "1.4.4", repos = "http://cran.us.r-project.org")
devtools::install_version("dbplyr", version = "1.4.4", repos = "http://cran.us.r-project.org")
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
mf1 <- copy_to(conn, tibble::tibble(x = 1), "df3", overwrite = TRUE )
val <- 1
mf2 <- mf1 %>% summarise(y = x == val) %>% collect()
View(mf2)
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
dbRemoveTable(conn, "df1")
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
dbRemoveTable(conn, "df1")
dbRemoveTable(conn, "df1")
dbRemoveTable(conn, "df2")
devtools::document()
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
dbRemoveTable(conn, "df3")
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(RHiveS2)
devtools::document()
devtools::document()
devtools::document()
library(dplyr)
library(rJava)
library(RJDBC)
library(dbplyr)
#library(RHiveS2)
devtools::load_all("/Users/zukow/Documents/GitHub/RHiveS2")
options(java.parameters = "-Xmx8g")
#dplyr_spark_connection
#
cp=c("/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar")
.jinit(classpath=cp)
# drv <- JDBC("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
# conn <- DBI::dbConnect(drv,"jdbc:hive2://localhost:10000","so_survey_2019_hive")
#drv <- HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2-standalone.jar",identifier.quote='`')
conn <- DBI::dbConnect(HiveS2("org.apache.hive.jdbc.HiveDriver","/Users/zukow/spark-2.2.1-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar",identifier.quote='`'),
host ="jdbc:hive2://localhost:",
port = "10000",
schema = "default"
)
dbListTables(conn)
